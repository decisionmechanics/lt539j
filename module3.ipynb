{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de88bf97-ca0e-42a5-99d6-e0bd1791d434",
   "metadata": {},
   "source": [
    "<img width=\"300px\" src=\"images/learning-tree-logo.svg\" alt=\"Learning Tree logo\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "568827eb-6be5-4ad7-9432-7bee9b0fb1d0",
   "metadata": {},
   "source": [
    "# Module 3: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ec24dd2-5aa2-4a5b-adcd-c38043880f98",
   "metadata": {},
   "source": [
    "In this module, we cover\n",
    "\n",
    "- Understanding datasets\n",
    "- Working wih large datasets\n",
    "- Creating tidy datasets\n",
    "- Data processing\n",
    "- Exploring relationships in the data\n",
    "- Dimensionality reduction\n",
    "- Hands-on example of using Python to explore and prepare a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2906eb-332d-4481-9421-f74b8c637807",
   "metadata": {},
   "source": [
    "The [notebooks](https://github.com/decisionmechanics/lt539j) for the course are available on GitHub. Clone or download them to follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354de74-ef9b-40e0-9f85-7ed4afe10187",
   "metadata": {},
   "source": [
    "In this notebook, we make use of the following third-party packages.\n",
    "\n",
    "```bash\n",
    "pip install jupyterlab duckdb numpy 'polars[all]' pyjanitor scikit-learn scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed549be-6c5c-4835-bbbc-66cd21f727ed",
   "metadata": {},
   "source": [
    "## Understanding datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5d9d4-732d-4cf6-90df-856c1da9b55e",
   "metadata": {},
   "source": [
    "Data comes in many different formats.\n",
    "\n",
    "- Tabular (e.g. CSV, Excel)\n",
    "- Semi-structured (e.g. JSON)\n",
    "- Text\n",
    "- Images\n",
    "- Videos\n",
    "- Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862992a3-ac44-4c1f-b6ff-3a155dccc1d6",
   "metadata": {},
   "source": [
    "When performing data reporting, or ML, we tend to work with tabular data. Even when working with so-called \"unstructured\" data, such as text, we convert it to a tablular form before analysing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901da5d-cf2e-4df1-abc8-7b54988f53b1",
   "metadata": {},
   "source": [
    "In traditional data analysis, we tend to have fields (or variables) that we can group on, summarise, etc.\n",
    "\n",
    "The fields can be of different types, such as\n",
    "\n",
    "- integer\n",
    "- float\n",
    "- text\n",
    "- logical\n",
    "- date\n",
    "- time\n",
    "- categorical\n",
    "\n",
    "Fields should be typed as tightly as possible. If a field should only ever contain dates, don't use a string to represent it.\n",
    "\n",
    "In tabluar data formats, fields are usually represented by the columns. Typical fields could be country name, continent, year, GDP, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c080e83-c8cb-4829-bcaa-acac93c9c0d6",
   "metadata": {},
   "source": [
    "The rows of a tabular dataset are the observations. Each observation has a value for each of the fields (or a null value, if the data is missing).\n",
    "\n",
    "Typical observations might be countries, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a6647-f3bf-4f4d-92ca-feecf0896128",
   "metadata": {},
   "source": [
    "When building ML models, we categorise the fields into features and targets.\n",
    "\n",
    "Features, also known as input or independent variables, are used to make the predicitions. They are the attributes of the obversations that we use to predict something of interest.\n",
    "\n",
    "The target is the something of interest. It's a value, or a class, that we are interested in knowing. Targets might be numeric, such as predicted profit, or categories, such as invest/don't invest.\n",
    "\n",
    "Targets, when they are given, are used to build supervised learning models.\n",
    "\n",
    "Note that fields are not fundamentally features or targets. Which group a field falls into depends on the specifics of the modelling activity. And not all fields will be features or targets. Some may be irrelevant to the modelling process (e.g. internal IDs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b2398-4305-4476-ae46-0a10d296ae87",
   "metadata": {},
   "source": [
    "Consider the following loan approval dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ee01e-19cc-45ff-ad2d-ef925075e23a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "(pl.read_csv(\"data/loan-approval-dataset.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecc990-2e96-4daf-8d1f-c72df1412bf2",
   "metadata": {},
   "source": [
    "We can view the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa96c66-922f-4902-8717-597657ad3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pl.read_csv(\"data/loan-approval-dataset.csv\").columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c7eb5-d958-4c72-9a19-75dd19e8ed79",
   "metadata": {},
   "source": [
    "With this dataset, we might want to classify loan applications into approved or rejected (i.e. `loan_status`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d80c2-0a82-43e6-b891-3da4d6294170",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pl.read_csv(\"data/loan-approval-dataset.csv\").select(\"loan_status\").unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a0357-d64b-4172-8c8a-39fce9e7017c",
   "metadata": {},
   "source": [
    "Note than this is a string field, but only has two values. We can convert this to a categorical (or logical) field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d76e00d-f498-40c7-8e62-9841d99680d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.StringCache():\n",
    "    loan_approval_df = pl.read_csv(\"data/loan-approval-dataset.csv\").with_columns(\n",
    "        pl.col(\"loan_status\").cast(pl.Categorical)\n",
    "    )\n",
    "\n",
    "(loan_approval_df.select(\"loan_status\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab357d-b139-4dd3-9c4f-312b922be6b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We can split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7280bb4-9912-46db-b5d5-fcc3baf1ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = loan_approval_df.drop([\"loan_id\", \"loan_status\"])\n",
    "\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a8d47-75b9-4700-9524-9ad0b9946e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = loan_approval_df.select([\"loan_status\"])\n",
    "\n",
    "target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702f60d-d60b-4bbe-8db1-e594c07a34d0",
   "metadata": {},
   "source": [
    "Best practice is to _explicitly_ define the fields to be _included_ in the result. So, we might revise the feature selection as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397e919-81d1-498f-bb2a-15a13e34abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    loan_approval_df.select(\n",
    "        [\n",
    "            \"no_of_dependents\",\n",
    "            \"education\",\n",
    "            \"self_employed\",\n",
    "            \"income_annum\",\n",
    "            \"loan_amount\",\n",
    "            \"loan_term\",\n",
    "            \"cibil_score\",\n",
    "            \"residential_assets_value\",\n",
    "            \"commercial_assets_value\",\n",
    "            \"luxury_assets_value\",\n",
    "            \"bank_asset_value\",\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b97af-5243-46b3-8c69-7041d165ba4a",
   "metadata": {},
   "source": [
    "More typing, but less opportunity for subtle errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74428e0-a60f-4d74-9b36-138ab4070c39",
   "metadata": {},
   "source": [
    "## Working with large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cdf7b2-54d6-4b11-9b1e-9381f33edb85",
   "metadata": {},
   "source": [
    "Polars allows us to work efficient with large datasets via it's [lazy API](https://docs.pola.rs/user-guide/lazy/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f9738-efe2-4e80-89bb-e765454a1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(\"data/shark-incidents.csv\", infer_schema_length=None)\n",
    "    .select([\"Shark.common.name\", \"Victim.injury\"])\n",
    "    .filter(~pl.all_horizontal(pl.all().is_null()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6e250-9ca6-48d6-ab5b-417a9a24fd38",
   "metadata": {},
   "source": [
    "The lazy API allows us to build up a query plan which can then be optimized before attempting to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03d6e9-3747-4af9-b665-4982394edeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(\"data/shark-incidents.csv\", infer_schema_length=None)\n",
    "    .select([\"Shark.common.name\", \"Victim.injury\"])\n",
    "    .filter(~pl.all_horizontal(pl.all().is_null()))\n",
    "    .show_graph()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a3fdbe-62ed-4a3c-bdb3-4eca899b41e7",
   "metadata": {},
   "source": [
    "To execute the plan we can `collect` the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26067e1-b495-4ddd-acb7-b940f02d1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(\"data/shark-incidents.csv\", infer_schema_length=None)\n",
    "    .select([\"Shark.common.name\", \"Victim.injury\"])\n",
    "    .filter(~pl.all_horizontal(pl.all().is_null()))\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8853e-eb7c-4114-9177-dd273742192b",
   "metadata": {},
   "source": [
    "For small datasets, it's convenient to use eager methods, such as `read_csv`. But, when your dataset is large, and you don't need all the data, using the lazy API can significantly improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee080e3-2ef8-44a9-9aaa-dc2e8cde9203",
   "metadata": {},
   "source": [
    "Another performance improvement is to use more efficient file formats. Parquet files, for example, store data by column. This makes it more efficient when you only want certain columns.\n",
    "\n",
    "Parquet files also store metadata, such as the column types (e.g. float, string), making them more suited to data analysis work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309fd7d-a068-41b9-8b5d-94800eac22a4",
   "metadata": {},
   "source": [
    "If you are going to be loading a CSV/Excel data file multiple times, it often makes sense to convert it to parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b7d9e-7ad3-45c9-bdb7-a802536dc1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(\"data/shark-incidents.csv\", infer_schema_length=None)\n",
    "    .filter(~pl.all_horizontal(pl.all().is_null()))\n",
    "    .collect()\n",
    "    .write_parquet(\"temp/shark-incidents.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6679a-bd34-4255-ad71-77835dcd4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_parquet(\"temp/shark-incidents.parquet\")\n",
    "    .select([\"Shark.common.name\", \"Victim.injury\"])\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8447ac-0911-4d62-8699-5546791f4fdb",
   "metadata": {},
   "source": [
    "We can see that, when you only need a subset of the data, parquet files can be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e4bea-bea7-43e7-b75d-a6796d37a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "(\n",
    "    pl.scan_parquet(\"temp/shark-incidents.parquet\")\n",
    "    .select([\"Shark.common.name\", \"Victim.injury\"])\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5fd0d-e175-464c-b978-05d081b0ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "(\n",
    "    pl.scan_csv(\"temp/shark-incidents.csv\", infer_schema_length=None)\n",
    "    .select([\"Shark.common.name\", \"Victim.injury\"])\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33548379-98c5-46e6-aee3-48472d5c0a41",
   "metadata": {},
   "source": [
    "[DuckDB](https://duckdb.org) is another efficient format for working with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681545f9-fd0a-4a7f-9b81-6c61f33dbdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import duckdb\n",
    "\n",
    "DB_FILE_PATH = \"temp/shark-incidents.db\"\n",
    "\n",
    "if os.path.isfile(DB_FILE_PATH):\n",
    "    os.remove(DB_FILE_PATH)\n",
    "\n",
    "shark_incidents_df = (\n",
    "    pl.scan_csv(\"temp/shark-incidents.csv\", infer_schema_length=None)\n",
    "    .rename(\n",
    "        {\n",
    "            \"Shark.common.name\": \"shark_common_name\",\n",
    "            \"Victim.injury\": \"victim_injury\",\n",
    "        }\n",
    "    )\n",
    "    .select(\n",
    "        [\n",
    "            \"shark_common_name\",\n",
    "            \"victim_injury\",\n",
    "        ]\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "\n",
    "database = duckdb.connect(DB_FILE_PATH)\n",
    "\n",
    "try:\n",
    "    database.sql(\"CREATE TABLE incidents AS SELECT * FROM shark_incidents_df\")\n",
    "finally:\n",
    "    database.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80ffca-bb24-462f-a273-86716c87b24d",
   "metadata": {},
   "source": [
    "## Creating tidy datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e485729c-f4dc-4b02-adf7-ffdb080f5c1c",
   "metadata": {},
   "source": [
    "When first encountering a dataset, it's important to have a quick look at the raw data. If it's a text format (e.g. CSV) you can look at it using CLI tools or open it in a text editor (such as Visual Studio Code)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb31456-6181-450e-9f74-d49831c84094",
   "metadata": {},
   "source": [
    "Consider the national GDP file downloaded in CSV format from the World Bank's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302b1fe-c4d1-4d24-a3c8-da0dd00a86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc10c8-930c-4431-a68b-1997cc2fd861",
   "metadata": {},
   "source": [
    "We can see that there's some preamble here that might cause a problem if we naively try to load it as a well-formed CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775d655-4a8a-497a-a295-28d71714aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\n",
    "        \"data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv\", truncate_ragged_lines=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c4b0b2-4ec4-4200-839c-40941b6b5bbc",
   "metadata": {},
   "source": [
    "Datasets often have problems at the end as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07688e84-c5e4-445a-a197-56698d1e2a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 5 data/shark-incidents.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33964894-6e62-488e-9e8b-065db7e07ad2",
   "metadata": {},
   "source": [
    "We can also investigate lines in the middle of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef379d3e-20cd-46ce-9d17-442b0d610f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_number = 20\n",
    "\n",
    "with open(\"data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv\") as f:\n",
    "    for index, line in enumerate(f):\n",
    "        if index == line_number - 1:\n",
    "            print(line)\n",
    "\n",
    "            break;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a66b5ba-ae01-4bc3-9c6c-61d8c1cd3abd",
   "metadata": {},
   "source": [
    "Or, if you prefer to use CLI tools, use the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936dfca-52f8-44b2-9714-87a792665895",
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk 'NR==20' data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7a454-e280-4a99-824e-a3c25d4f37c3",
   "metadata": {},
   "source": [
    "Note the trailing comma on the end of the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5022a25-99ca-4191-bfef-98d85877b091",
   "metadata": {},
   "source": [
    "Just getting the data into a useful tabular format can involve a significant amount of custom coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa969bf9-b2bc-4d59-8be8-99ff2345505a",
   "metadata": {},
   "source": [
    "Let's get the World Bank GDP data into a form we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661051c0-98bd-47fb-bb73-6e220e1911f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = pl.read_csv(\"data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv\", skip_rows=4)\n",
    "\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a821c2-9c3a-4a89-8aa0-47f03f6f4f7e",
   "metadata": {},
   "source": [
    "When a data frame is read, it makes sense to normalise the names. The `pyjanitor` package can do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ac3ad-aec7-4825-ab24-3b37e1b21e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import janitor.polars\n",
    "\n",
    "gdp_df = pl.read_csv(\n",
    "    \"data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv\", skip_rows=4\n",
    ").clean_names()\n",
    "\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b27338-06e8-4a50-aee1-00672235adc7",
   "metadata": {},
   "source": [
    "It's now in a form where we have access to the correct values. But it's still not ideal.\n",
    "\n",
    "First thing to note is that we have a spurious column at the end. We can remove that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9707726-c8fc-4899-b810-5bc4051ac5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = (\n",
    "    pl.read_csv(\"data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv\", skip_rows=4)\n",
    "    .clean_names()\n",
    "    .drop(\"\")\n",
    ")\n",
    "\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38154b53-aaf1-49f4-bf9d-ad87aea6a3cc",
   "metadata": {},
   "source": [
    "This dataset isn't in [tidy format](https://tidyr.tidyverse.org/articles/tidy-data.html).\n",
    "\n",
    "> [In a tidy dataset,] every value belongs to a variable and an observation. A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. An observation contains all values measured on the same unit (like a person, or a day, or a race) across attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b370919-db01-43dc-842a-02467535dc4a",
   "metadata": {},
   "source": [
    "In the World Bank dataset, the year is a field, but it's defined across multiple columns. This makes is harder to work with, and results in lots of blank \"cells\" due to missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b60653-f60a-453b-9870-c492ea144212",
   "metadata": {},
   "source": [
    "We can unpivot the \"worksheet\" format to a tidy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad399e-d002-42a8-8eba-6c8fb20f9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gdp_df.unpivot(\n",
    "        index=[\"country_name\", \"country_code\", \"indicator_name\", \"indicator_code\"],\n",
    "        variable_name=\"year\",\n",
    "        value_name=\"gdp\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3fa762-643a-465d-8ad1-9b796fa96a74",
   "metadata": {},
   "source": [
    "This is cleaner, but there are now a lot of missing (\"\") values. We can replace those with nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37127f-da4c-4af1-92f1-46060245bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gdp_df.unpivot(\n",
    "        index=[\"country_name\", \"country_code\", \"indicator_name\", \"indicator_code\"],\n",
    "        variable_name=\"year\",\n",
    "        value_name=\"gdp\",\n",
    "    ).with_columns(\n",
    "        pl.col(\"year\").replace(\"\", None),\n",
    "        pl.col(\"gdp\").replace(\"\", None),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d3412-95a9-4eb2-88b7-6b0413209dca",
   "metadata": {},
   "source": [
    "We can see that every field is using the string data type. `year` should really be an integer and `gdp` a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c89397c-fac4-4bb4-b1fc-70748c4fdd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gdp_df.unpivot(\n",
    "        index=[\"country_name\", \"country_code\", \"indicator_name\", \"indicator_code\"],\n",
    "        variable_name=\"year\",\n",
    "        value_name=\"gdp\",\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"year\").replace(\"\", None),\n",
    "        pl.col(\"gdp\").replace(\"\", None),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"year\").cast(pl.UInt16),\n",
    "        pl.col(\"gdp\").cast(pl.Float64),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bc121-c061-4b6a-b0b6-e9f3fda14000",
   "metadata": {},
   "source": [
    "Now what we've cleaned the data up, we can bring it all together and store it as a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de4607-ee27-4e3b-a70d-ad77084ab85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(\"data/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_31795.csv\", skip_rows=4)\n",
    "    .clean_names()\n",
    "    .unpivot(\n",
    "        index=[\"country_name\", \"country_code\", \"indicator_name\", \"indicator_code\"],\n",
    "        variable_name=\"year\",\n",
    "        value_name=\"gdp\",\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"year\").replace(\"\", None),\n",
    "        pl.col(\"gdp\").replace(\"\", None),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"year\").cast(pl.UInt16),\n",
    "        pl.col(\"gdp\").cast(pl.Float64),\n",
    "    )\n",
    "    .write_parquet(\"temp/world-bank-gdp.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a535ddc-47a6-410d-88b0-5e840af390eb",
   "metadata": {},
   "source": [
    "Read it back in to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547ccea-6dd8-4ad7-98fe-93200aa151dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_parquet(\"temp/world-bank-gdp.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd506a-4813-4076-a08b-2d6a1c5333af",
   "metadata": {},
   "source": [
    "Note that it might have made sense to filter out observations with missing values, convert some of the string fields to categoricals and remove fields with single values before saving as a parquet file. We will look at performing these operations in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0284b3-25c6-4241-9243-76b3783ed976",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a35f2-f7af-43cc-a499-d8e2e57f7401",
   "metadata": {},
   "source": [
    "Load the World Bank's GDP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39d600-fa6e-4da4-8852-8a29b7280d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = pl.read_parquet(\"temp/world-bank-gdp.parquet\")\n",
    "\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80489d8-34f8-4eda-9db3-fef82f0775c1",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ab0ec-18ff-4736-a7b6-d5486be5ada6",
   "metadata": {},
   "source": [
    "Clearly, there's some missing GDP values (and years). How many values are missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb78fc1-c4fe-479e-88c0-67e3604922e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df.null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f85de-b3b6-4941-a61d-8754273b2d10",
   "metadata": {},
   "source": [
    "Let's drop the observations that don't have a GDP value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59d123-2bad-43af-a4b7-3ede0120b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = pl.read_parquet(\"temp/world-bank-gdp.parquet\").filter(\n",
    "    pl.col(\"gdp\").is_not_null(),\n",
    ")\n",
    "\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dcd25e-51cf-4bfa-aa4d-69610f033aa7",
   "metadata": {},
   "source": [
    "Any missing values now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07511b06-2a57-47bc-a0ab-c5f1b3269872",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df.null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8029b0-8dd3-46ab-858b-30bc93b71a6c",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21d8d6-057f-45f1-8a4e-d3084a35e7f2",
   "metadata": {},
   "source": [
    "The string fields in this dataset could be considered categoricals. Let's change their type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505fa03-e628-4415-b6de-fdf622b81278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.selectors as cs\n",
    "\n",
    "gdp_df = (\n",
    "    pl.read_parquet(\"temp/world-bank-gdp.parquet\")\n",
    "    .filter(\n",
    "        pl.col(\"gdp\").is_not_null(),\n",
    "    )\n",
    "    .with_columns(\n",
    "        (~cs.numeric()).cast(pl.Categorical),\n",
    "    )\n",
    ")\n",
    "\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fabacc-9379-4d36-9fec-3e6474f5468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a002623-92e9-47b4-829a-beaac87ba3e0",
   "metadata": {},
   "source": [
    "Is there more than one indicator in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d0896-5571-411c-91b9-9204b3a0fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gdp_df.select([\"indicator_name\", \"indicator_code\"]).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9435cbbf-6cd3-4944-8d72-51241adea5e3",
   "metadata": {},
   "source": [
    "As these columns don't add anything, we can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832914a-e26d-41f0-b841-42dc81280fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = (\n",
    "    pl.read_parquet(\"temp/world-bank-gdp.parquet\")\n",
    "    .filter(\n",
    "        pl.col(\"gdp\").is_not_null(),\n",
    "    )\n",
    "    .with_columns(\n",
    "        (~cs.numeric()).cast(pl.Categorical),\n",
    "    )\n",
    "    .drop([\"indicator_name\", \"indicator_code\"])\n",
    ")\n",
    "\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f1bd5-e4d6-409b-9af4-72d7e6bc22a9",
   "metadata": {},
   "source": [
    "Are there any duplicated observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126d44a-6e47-483f-a83b-69ccc56d36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gdp_df.drop(\"gdp\").filter(gdp_df.is_duplicated()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdc57c-5704-4a5c-9c9d-0987df6a05a5",
   "metadata": {},
   "source": [
    "When working with categorical data, we sometimes want to convert it to multiple columns that signify the presence or absence of a given _value_.\n",
    "\n",
    "This makes it easy for ML algorithms to include the information conveyed by the categorical field.\n",
    "\n",
    "This approach is known as onehot encoding. And the new present/absent fields are know as dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3033c-51ce-41f7-9411-d92ceb00823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_incident_df = pl.read_parquet(\"data/shark-incidents.parquet\")\n",
    "\n",
    "(\n",
    "    shark_incident_df.select(\"state\")\n",
    "    .with_columns(pl.col(\"state\").alias(\"temporary_state\"))\n",
    "    .to_dummies(\"state\", drop_first=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45da1c-35c1-4a63-a958-24417d4e8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(shark_incident_df.select(cs.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35caab1-cf93-4b5b-bd85-ecdf9e07b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_incident_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece66e9-b20f-4815-a338-a009fa443b73",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9092d8dc-10ad-4fd3-9b5f-87a1b0673f4b",
   "metadata": {},
   "source": [
    "When data is at very different scales, it can confuse some ML algorithms---or at least make them less efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc32a8-016c-4f95-a187-c0e69e4580a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_height_df = pl.DataFrame(\n",
    "    {\n",
    "        \"weight_g\": [80_000, 81_000, 82_000, 83_000],\n",
    "        \"height_m\": [1.87, 1.86, 1.57, 1.56],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdb509-f258-4521-8c8a-da9eac00be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    weight_height_df.plot.point(\n",
    "        x=\"weight_g\",\n",
    "        y=\"height_m\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba978a2-11f1-446e-8aaf-aa1dc8073014",
   "metadata": {},
   "source": [
    "Plotting data automatically scales it. Points 1 and 2 appear to be close, although they are over 1000 units apart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3ee116-e9cf-4e28-b155-a34748069633",
   "metadata": {},
   "source": [
    "We can normalise the fields by transforming them to z-scores---values with a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ddb295-9d28-4287-a3b0-1349ece1b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "weight_height_z_score_df = pl.from_numpy(\n",
    "    zscore(weight_height_df.to_numpy(), ddof=1)\n",
    ").pipe(lambda df_: df_.rename(dict(zip(df_.columns, weight_height_df.columns))))\n",
    "\n",
    "weight_height_z_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7c838-d63c-443e-8df9-277cd513cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_height_z_score_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745f80a-4363-4d13-8e19-6bf5bd4bc5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_height_z_score_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1110b8-c0a2-44a1-9d4d-5c3d5009778d",
   "metadata": {},
   "source": [
    "Note that this doesn't change the _relationships_ in the dataset---just the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74765c-7337-440f-b028-bd853d9f0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    weight_height_z_score_df.plot.point(\n",
    "        x=\"weight_g\",\n",
    "        y=\"height_m\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4441c1-8a45-4e72-89cf-bd353f5cdb22",
   "metadata": {},
   "source": [
    "## Exploring relationships in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89271543-bb86-4d9b-9aef-2ac825c760b0",
   "metadata": {},
   "source": [
    "Understanding a dataset involves exploring the relationships in the data. Key relationships include\n",
    "\n",
    "- Relationships between the values in a field (e.g. their distribution)\n",
    "- Relationships between fields (correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15e955-a04d-4bfc-83ac-b24e0324366f",
   "metadata": {},
   "source": [
    "Consider the World Bank's GDP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444af898-15b6-476a-b085-854d76e1c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df = pl.read_csv(\"data/world-bank-gdp.csv\")\n",
    "\n",
    "gdp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d891829d-5c31-4a03-95ab-6a5ed110238b",
   "metadata": {},
   "source": [
    "We can look at how the UK's GDP has changed over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0edb6d-0f63-4805-83df-74c9b175f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "(\n",
    "    gdp_df.filter(\n",
    "        pl.col(\"country_code\") == \"GBR\",\n",
    "    )\n",
    "    .plot.line(x=\"year\", y=\"gdp\")\n",
    "    .properties(width=500, height=200)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5017535-6245-48e1-84c8-be796d14d54b",
   "metadata": {},
   "source": [
    "We can also look at the distribution of GDP/capita for 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a047456-0a8f-49fa-953b-f3e162a2f032",
   "metadata": {},
   "source": [
    "Note that the following code should work, but there's a bug at the time of writing.\n",
    "\n",
    "```python\n",
    "(\n",
    "    gdp_df.with_columns((pl.col(\"gdp\") / pl.col(\"population\")).alias(\"gdp_per_capita\"))\n",
    "    .filter(\n",
    "        pl.col(\"year\") == 2023,\n",
    "    )\n",
    "    .plot.boxplot(x=\"gdp\")\n",
    "    .properties(width=500, height=200)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5607d9-dabd-4100-b658-e5622509ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.Chart(\n",
    "    gdp_df.with_columns(\n",
    "        (pl.col(\"gdp\") / pl.col(\"population\")).alias(\"gdp_per_capita\")\n",
    "    ).filter(\n",
    "        pl.col(\"year\") == 2023,\n",
    "    )\n",
    ").mark_boxplot().encode(alt.X(\"gdp_per_capita\")).properties(width=500, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7585578-08b1-4316-aa5b-eae57182d045",
   "metadata": {},
   "source": [
    "Or the correlation between population and GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74827ff5-d530-4815-808d-66330e938d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gdp_df.filter(\n",
    "        pl.col(\"year\") == 2023,\n",
    "    )\n",
    "    .plot.point(x=\"population\", y=\"gdp\")\n",
    "    .properties(width=500, height=200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f39c0c1-6759-4dc4-9711-6731d580a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_df.select(pl.corr(\"population\", \"gdp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd8ae8-032e-4697-945e-c3d2aa3adab3",
   "metadata": {},
   "source": [
    "Let's look at some data from a [research paper](https://www.pnas.org/doi/abs/10.1073/pnas.1209746109). This paper was retracted in 2021.\n",
    "\n",
    "We'll examine the dataset underlying the conclusions and see why there were [serious concerns](https://datacolada.org/98) about the research.\n",
    "\n",
    "The research claimed to show that having people signing a statement of honest intent _prior_ to completing a form made their disclosures more truthful than if you asked them to sign it at the _end_ of the form.\n",
    "\n",
    "They choose to demonstrate this using car insurance data, where drivers were required to submit odometer readings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a0bbf-0f75-4076-9640-539d09bf66ec",
   "metadata": {},
   "source": [
    "The original data is in an Excel workbook (DrivingdataAll (1).xls). We'll use a cleaned up version (e.g. cleaner column names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb15a1-1032-4555-9e63-0c74c22b6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dishonesty_study_df = pl.read_parquet(\"data/dishonesty-study.parquet\")\n",
    "\n",
    "dishonesty_study_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c309aed-4d22-47b1-92f3-7873d77b93f7",
   "metadata": {},
   "source": [
    "Customers can have up to four cars. Baseline and updated odometer read are provided for each car. The baseline readings were earlier readings supplied to the company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c69012-e4cb-4707-a373-f8011a8d3187",
   "metadata": {},
   "source": [
    "Let's consider the miles driven in car 1 during the period between the baseline reading and the updated reading. We have data on how many miles people drive per year.\n",
    "\n",
    "![Annual mileage per car](https://www.bymiles.co.uk/wp-content/uploads/2023/12/MOT-Data-2024-Annual-mileage-car@3x-1-1000x669.png)\n",
    "\n",
    "Some people don't drive at all, a lot of people drive a little, and a few drive a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef03eba-9877-4a1e-92d5-58a9acce94dc",
   "metadata": {},
   "source": [
    "Here's the distribution from the data in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd2322-00c0-4689-97a1-d495f70a3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dishonesty_study_df.with_columns(\n",
    "        (pl.col(\"update_car_1\") - pl.col(\"baseline_car_1\")).alias(\"miles_driven_car_1\")\n",
    "    )\n",
    "    .get_column(\"miles_driven_car_1\")\n",
    "    .hist(bin_count=50)\n",
    "    .plot.bar(\n",
    "        x=\"breakpoint\",\n",
    "        y=\"count\",\n",
    "    )\n",
    "    .properties(width=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc843d1b-aec3-4ec7-a999-f639b8019199",
   "metadata": {},
   "source": [
    "That's pretty much a uniform distribution that runs from 0 to 50,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d85808-90b4-4a77-babc-50aa6bc6c967",
   "metadata": {},
   "source": [
    "The distributions for the other cars are similarly problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b66562-3217-4dfa-a379-3784215e3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dishonesty_study_df.with_columns(\n",
    "        (pl.col(\"update_car_4\") - pl.col(\"baseline_car_4\")).alias(\"miles_driven_car_4\")\n",
    "    )\n",
    "    .get_column(\"miles_driven_car_4\")\n",
    "    .hist(bin_count=50)\n",
    "    .plot.bar(\n",
    "        x=\"breakpoint\",\n",
    "        y=\"count\",\n",
    "    )\n",
    "    .properties(width=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053cb12-4f7d-4092-899e-b56e4d39581b",
   "metadata": {},
   "source": [
    "When people estimate car mileages they tend to round them. We can see this in the baseline data for car 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa92c7-16a4-4962-9178-baeaa283883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dishonesty_study_df.with_columns(\n",
    "        (pl.col(\"baseline_car_1\") % 1000).alias(\"baseline_car_1_rounding_3\")\n",
    "    )\n",
    "    .get_column(\"baseline_car_1_rounding_3\")\n",
    "    .value_counts()\n",
    "    .with_columns((pl.col(\"count\") / pl.sum(\"count\")).alias(\"proportion\"))\n",
    "    .plot.bar(\n",
    "        x=\"baseline_car_1_rounding_3\",\n",
    "        y=alt.Y(\"proportion\", scale=alt.Scale(domain=[0, 0.12])),\n",
    "    )\n",
    "    .properties(width=800)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e61ed-87b3-421a-b432-548af9d10617",
   "metadata": {},
   "source": [
    "However, when we look at the updated data for car one, we see no evidence of rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82f477-e6e6-4dff-97df-5c787cacc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dishonesty_study_df.with_columns(\n",
    "        (pl.col(\"update_car_1\") % 1000).alias(\"update_car_1_rounding_3\")\n",
    "    )\n",
    "    .get_column(\"update_car_1_rounding_3\")\n",
    "    .value_counts()\n",
    "    .with_columns((pl.col(\"count\") / pl.sum(\"count\")).alias(\"proportion\"))\n",
    "    .plot.bar(\n",
    "        x=\"update_car_1_rounding_3\",\n",
    "        y=alt.Y(\"proportion\", scale=alt.Scale(domain=[0, 0.12])),\n",
    "    )\n",
    "    .properties(width=800)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cefeba-5e9e-4a54-a190-008105e5dac3",
   "metadata": {},
   "source": [
    "How about looking at the frequency of the last digit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571f70a-b93a-4d20-9778-fae430b5f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dishonesty_study_df.with_columns(\n",
    "        (pl.col(\"baseline_car_1\") % 10).alias(\"baseline_car_1_rounding_1\")\n",
    "    )\n",
    "    .get_column(\"baseline_car_1_rounding_1\")\n",
    "    .value_counts()\n",
    "    .with_columns((pl.col(\"count\") / pl.sum(\"count\")).alias(\"proportion\"))\n",
    "    .plot.bar(\n",
    "        x=\"baseline_car_1_rounding_1\",\n",
    "        y=alt.Y(\"proportion\", scale=alt.Scale(domain=[0, 0.25])),\n",
    "    )\n",
    "    .properties(width=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee30ce6-ac1e-4005-bf97-4dfe87794ebe",
   "metadata": {},
   "source": [
    "Again, the updated data doesn't look right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349e45b-fb67-4736-ae0f-dab4f59658e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dishonesty_study_df.with_columns(\n",
    "        (pl.col(\"update_car_1\") % 10).alias(\"update_car_1_rounding_1\")\n",
    "    )\n",
    "    .get_column(\"update_car_1_rounding_1\")\n",
    "    .value_counts()\n",
    "    .with_columns((pl.col(\"count\") / pl.sum(\"count\")).alias(\"proportion\"))\n",
    "    .plot.bar(\n",
    "        x=\"update_car_1_rounding_1\",\n",
    "        y=alt.Y(\"proportion\", scale=alt.Scale(domain=[0, 0.25])),\n",
    "    )\n",
    "    .properties(width=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8788d06-5ba3-4f22-a025-8c6b98d75d16",
   "metadata": {},
   "source": [
    "There was an intriguing formatting issue in the worksheet. _Exactly_ half of the values in the the `baseline_car_1` column were displayed using the Cambria font. The other half used Calibri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a371f19-332b-4021-bf2f-5d1c9e87d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dishonesty_study_df.filter(pl.col(\"font\") == \"Cambria\").select(pl.len()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7044c4-bd23-41bd-9447-5dad9b64c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dishonesty_study_df.filter(pl.col(\"font\") == \"Calibri\").select(pl.len()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942924f5-3d2d-4c4c-80e6-a7ce4a9e01e4",
   "metadata": {},
   "source": [
    "We can split the dataset by font, with each font field sorted by `baseline_car_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d787b0-5596-4d05-9810-e79448bf6092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "font_df = pl.DataFrame(\n",
    "    {\n",
    "        \"cambria\": dishonesty_study_df.filter(pl.col(\"font\") == \"Cambria\")\n",
    "        .sort(\"baseline_car_1\")\n",
    "        .get_column(\"baseline_car_1\"),\n",
    "        \"calibri\": dishonesty_study_df.filter(pl.col(\"font\") == \"Calibri\")\n",
    "        .sort(\"baseline_car_1\")\n",
    "        .get_column(\"baseline_car_1\"),\n",
    "    }\n",
    ").with_columns((pl.col(\"cambria\") - pl.col(\"calibri\")).alias(\"difference\"))\n",
    "\n",
    "font_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ca327-922f-49c0-bc4f-6aff2a4698cd",
   "metadata": {},
   "source": [
    "Is there a correlation between these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d78cb-3dcc-41ac-b0fe-8c2a59f14b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_df.select(pl.corr(\"cambria\", \"calibri\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ee775-7d63-48aa-be5f-6fa416ca61b0",
   "metadata": {},
   "source": [
    "How is the difference between the two columns distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa3fb3-ed10-4d96-a9c7-3403b3e052d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    font_df.get_column(\"difference\")\n",
    "    .hist(bin_count=50)\n",
    "    .plot.bar(x=\"breakpoint\", y=\"count\")\n",
    "    .properties(width=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d49d3e-36a4-476c-9450-8e02def18848",
   "metadata": {},
   "source": [
    "Could someone have copied all the data and added a random number with some distribution running between 0 and 1000?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc2f68-4fde-4b1a-ac7a-c093d5ad295d",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ac613-9c9c-4f42-8e8c-115e05c64e5f",
   "metadata": {},
   "source": [
    "High dimensional data (i.e. many features) can result in performance and accuracy problems in ML. This is often referred to as the curse of dimensionality.\n",
    "\n",
    "There are techniques that allow us to to reduce the dimensionality of the data, while minimising the loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd2683-5285-4ca9-9bc5-51ae25aad04f",
   "metadata": {},
   "source": [
    "Consider the following (meaningless) dataset with two features in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dda1c3-702a-4382-81f5-be926a5a2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "original_data = np.stack(\n",
    "    [\n",
    "        [\n",
    "            0.72366164,\n",
    "            1.44194784,\n",
    "            2.20955984,\n",
    "            2.89736675,\n",
    "            3.43509835,\n",
    "            4.17267258,\n",
    "            4.91907454,\n",
    "            5.70487071,\n",
    "            6.40549306,\n",
    "            6.93480835,\n",
    "        ],\n",
    "        [\n",
    "            0.69055192,\n",
    "            1.38647928,\n",
    "            2.03308085,\n",
    "            2.7594875,\n",
    "            3.63596946,\n",
    "            4.31260879,\n",
    "            4.9804204,\n",
    "            5.60883779,\n",
    "            6.322429,\n",
    "            7.20732728,\n",
    "        ],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093573e9-a4c6-49ad-ad95-d53f59820dc6",
   "metadata": {},
   "source": [
    "Here's how it looks when plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25190e-99c3-46d4-8932-19b54fa7ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlim(-1, 11)\n",
    "plt.ylim(-1, 11)\n",
    "\n",
    "plt.scatter(x=original_data[0], y=original_data[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186aed70-387a-4222-b9ec-952c789695a7",
   "metadata": {},
   "source": [
    "If we rotate this data 45&deg;, we reposition it with respect to the axes, but retain all the relationships between the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b47a6-9825-4e49-a9aa-2f4361ace276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rotate_points(points, theta):\n",
    "    theta_radians = theta * np.pi / 180\n",
    "\n",
    "    rotation = [\n",
    "        [np.cos(theta_radians), -np.sin(theta_radians)],\n",
    "        [np.sin(theta_radians), np.cos(theta_radians)],\n",
    "    ]\n",
    "\n",
    "    return rotation @ points\n",
    "\n",
    "\n",
    "transformed_data = rotate_points(original_data, -45)\n",
    "\n",
    "plt.xlim(-1, 11)\n",
    "plt.ylim(-1, 11)\n",
    "\n",
    "plt.scatter(x=original_data[0], y=original_data[1], color=\"#ccc\")\n",
    "plt.scatter(x=transformed_data[0], y=transformed_data[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4fe1a-bca6-4b9d-b0fd-29315cff40eb",
   "metadata": {},
   "source": [
    "Note how the majority of the variation in this data is across the x-axis. There's very little variation in across the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ece5e-230b-4a65-a65d-6a9e62b75013",
   "metadata": {},
   "source": [
    "If we set the y values to 0, we now have a one-dimensional (single feature) dataset that retains the bulk of the variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf7b32-9903-4e81-8512-516b400a2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=transformed_data[0], y=np.zeros(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f02b1f-00aa-431c-af3e-6f7600b178c9",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6b25f-450e-4eec-b992-b4009b039258",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a popular dimensionality reduction approach.\n",
    "\n",
    "We'll use it here to reduce the dimensionality of the [Palmer penguins dataset](https://allisonhorst.github.io/palmerpenguins/articles/intro.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5547da6-53a8-4975-9325-5cc1081bc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_df = pl.read_csv(\"data/penguins.csv\").drop_nulls()\n",
    "\n",
    "penguin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc391d8-3f63-4361-872b-304d69092b40",
   "metadata": {},
   "source": [
    "PCA cant handle missing values, so well just remove observations with missing data. \n",
    "\n",
    "Probabilistic PCA (PPCA) can be used when you have missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e57c60-9442-4ecd-b951-916feb508cdb",
   "metadata": {},
   "source": [
    "PCA only works with numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc4fa1-e5d9-4e68-8ece-948b7d884e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_numeric_df = penguin_df.select(cs.numeric().exclude(\"year\"))\n",
    "\n",
    "penguin_numeric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc9af16-3777-4747-83ba-52b29235f498",
   "metadata": {},
   "source": [
    "PCA is affected by scale, so we'll convert our dataset to z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60251d36-1fdb-469f-be6d-7cae837daa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_z_score_df = pl.from_numpy(zscore(penguin_numeric_df.to_numpy(), ddof=1)).pipe(\n",
    "    lambda df_: df_.rename(dict(zip(df_.columns, penguin_numeric_df.columns)))\n",
    ")\n",
    "\n",
    "penguin_z_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a6e57-fca9-4229-93e2-810b28e0c38f",
   "metadata": {},
   "source": [
    "Transform the dataset to its principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1d0c5-5fe7-4966-89a0-82db82ec0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "principal_components = pca.fit_transform(penguin_z_score_df.to_numpy())\n",
    "\n",
    "principal_component_df = pl.concat(\n",
    "    [\n",
    "        penguin_df.select(\"species\"),\n",
    "        pl.from_numpy(\n",
    "            principal_components,\n",
    "            [\"component1\", \"component2\", \"component3\", \"component4\"],\n",
    "        ),\n",
    "    ],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "\n",
    "principal_component_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f9dc4-484e-4ce2-b511-81d6ee3658a3",
   "metadata": {},
   "source": [
    "How much of the variable is explained by each principal component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2b239-821a-4567-bd87-129d6ca5f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76862a6f-fe2f-4fc7-9942-60c1ee239d85",
   "metadata": {},
   "source": [
    "We can see that 88% of the total variance is explained by the first two components.\n",
    "\n",
    "This lets us visualise the data as a two-dimensional scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3548f-73c3-4303-ac8c-e9628f17ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    principal_component_df.plot.point(\n",
    "        x=\"component1\", y=\"component2\", color=\"species\"\n",
    "    ).properties(width=500, height=500)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b25ad-bb1b-4c25-a0bd-a32721739cbd",
   "metadata": {},
   "source": [
    "We can see that the Gentoos can be trivially identified, but seperating the Adelies from the Chinstraps is more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00ee0b-1274-4bc4-8535-19b02fd452af",
   "metadata": {},
   "source": [
    "## Hands-on example of using Python to explore and prepare a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345cb1c-4f6c-4e4f-a42b-ff552ad827df",
   "metadata": {},
   "source": [
    "Explore a [movie dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset) from Kaggle.\n",
    "\n",
    "There are two CSV files.\n",
    "\n",
    "- `movies.csv` which contains data about the movies\n",
    "- `movie_ratings.csv` which contains ratings for the movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5bd9f2-cfb1-45d7-8b04-c43eba7b49fe",
   "metadata": {},
   "source": [
    "Check the top and bottom of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ec40d-0de0-4565-8284-db97f83570e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 3 data/movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01838707-f5f6-461a-a8d4-2594258bdb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 3 data/movies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab7d4f-76e8-4871-845e-f77404bab7ad",
   "metadata": {},
   "source": [
    "Looks like a valid CSV file. Load it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb91de-817c-4ca3-9a90-7e61c35f0197",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pl.read_csv(\"data/movies.csv\")\n",
    "\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4bff5-3861-49d1-bb15-66189dc98d6c",
   "metadata": {},
   "source": [
    "Get a summary of the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602491f8-fd46-4cd1-acdc-5e322456fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f990d-a9f0-4df7-afc4-ad4dd1270e81",
   "metadata": {},
   "source": [
    "The column names look clean, so there's no need to transform them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61efd513-0886-4d02-b290-980a0ad114f8",
   "metadata": {},
   "source": [
    "The data type of the `release_date` field doesn't seem to have been inferred correctly. Convert it to a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27675668-c3d6-4803-aed8-58ebe2e6ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pl.read_csv(\"data/movies.csv\").with_columns(\n",
    "    pl.col(\"release_date\").str.to_date()\n",
    ")\n",
    "\n",
    "movie_df.glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70dcc7d-3c62-44ef-aa02-8be4a95222f7",
   "metadata": {},
   "source": [
    "Is there any missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e02b49-4fa4-48d9-916b-5d9a3b862e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84c32b-084c-4535-80ea-eea5c5136806",
   "metadata": {},
   "source": [
    "Yes, but probably not in the important fields. Seems pretty clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5737d54-a9a5-4af2-ad88-15506512d4d9",
   "metadata": {},
   "source": [
    "Examine the revenue distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49197f72-a7ba-46c8-98ac-1d398ad0dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_df.get_column(\"revenue\").hist(bin_count=50).plot.bar(x=\"breakpoint\", y=\"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6872b-f395-484a-a167-4e87259aec36",
   "metadata": {},
   "source": [
    "Quite a lot of movies with low revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1966ae0-d52a-4350-a365-da7a3b9b9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_df.sort(\"revenue\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f24a13-aead-4adf-b7bf-106b2c18122f",
   "metadata": {},
   "source": [
    "Movies with $0 revenue (and $0 budget) seem unlikely. Some data issues there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf210a-fe06-4e77-97f9-f705c80d6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.filter(\n",
    "        pl.col(\"revenue\") > 0,\n",
    "    )\n",
    "    .get_column(\"revenue\")\n",
    "    .hist(bin_count=50)\n",
    "    .plot.bar(x=\"breakpoint\", y=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880267ef-ab90-4a32-854d-6e85ce7b13a3",
   "metadata": {},
   "source": [
    "That looks more reasonable. What about movies that made less than $500m?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113d755-ccc3-4133-bc80-bbb20b146513",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.filter(\n",
    "        pl.col(\"revenue\") > 0,\n",
    "        pl.col(\"revenue\") < 500_000_000,\n",
    "    )\n",
    "    .get_column(\"revenue\")\n",
    "    .hist(bin_count=50)\n",
    "    .plot.bar(x=\"breakpoint\", y=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1552e-2ffd-4c47-984f-8b6b3bf974d6",
   "metadata": {},
   "source": [
    "How is `budget` distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4265189-a7ce-499e-91df-348206dbad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.filter(\n",
    "        pl.col(\"budget\") > 0,\n",
    "    )\n",
    "    .get_column(\"budget\")\n",
    "    .hist(bin_count=50)\n",
    "    .plot.bar(x=\"breakpoint\", y=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2944d51-7873-4dcf-806a-58a454074cda",
   "metadata": {},
   "source": [
    "Is there a relationship between budget and revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e16747-2b85-426c-9b69-b2cec73e9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_sample_df = movie_df.filter(\n",
    "    pl.col(\"budget\") > 0,\n",
    "    pl.col(\"revenue\") > 0,\n",
    ").sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dba62d-7759-4dfd-b198-715fc261eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_sample_df.plot.point(x=\"budget\", y=\"revenue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a882114-83c7-475c-8b04-6ed6519a1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.filter(\n",
    "        pl.col(\"budget\") > 0,\n",
    "        pl.col(\"revenue\") > 0,\n",
    "    ).select(\n",
    "        pl.corr(\"budget\", \"revenue\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8677c4-e4ab-4ff7-966d-0ffea88dbdb2",
   "metadata": {},
   "source": [
    "What period is covered by the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b89c02-e17a-4996-8392-32ab54a40b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.select(\n",
    "        [\n",
    "            pl.min(\"release_date\").alias(\"min_release_date\"),\n",
    "            pl.max(\"release_date\").alias(\"max_release_date\"),\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c571956-999d-48f5-b6e8-306fe888f32c",
   "metadata": {},
   "source": [
    "How is `runtime` distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d6919-ec20-461b-84cd-f79ec839538e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.filter(\n",
    "        pl.col(\"runtime\") > 0,\n",
    "        pl.col(\"runtime\") < 240,\n",
    "    )\n",
    "    .get_column(\"runtime\")\n",
    "    .hist(bin_count=50)\n",
    "    .plot.bar(x=\"breakpoint\", y=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47318b96-fb52-4e41-b9c0-f6a26915abc4",
   "metadata": {},
   "source": [
    "How does it look if you remove the filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca9485-3b56-4293-87b2-7bf7864d394a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(movie_df.get_column(\"runtime\").hist(bin_count=50).plot.bar(x=\"breakpoint\", y=\"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65724e-8770-4c80-bb5d-b99cc48d1245",
   "metadata": {},
   "source": [
    "Explore the rating data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa44df-3cdf-49f7-a8d2-5a6d1b72b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating_df = pl.read_csv(\"data/movie-ratings-sample.csv\").rename(\n",
    "    {\n",
    "        \"userId\": \"user_id\",\n",
    "        \"movieId\": \"movie_id\",\n",
    "    }\n",
    ")\n",
    "\n",
    "movie_rating_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11eb7d8-93ae-4a4c-a33a-8d15044d6f4a",
   "metadata": {},
   "source": [
    "View the distribution of the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151ecbe-6dd1-4b7f-b1a3-746373ac73e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_rating_df.get_column(\"rating\").value_counts().plot.bar(x=\"rating\", y=\"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0fd7a-2d2a-4874-b2cb-efd23a1f75e2",
   "metadata": {},
   "source": [
    "Does this seem OK?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e828d28-7b80-419d-9ded-218db7eaefbd",
   "metadata": {},
   "source": [
    "What's the average rating for horror movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a256d-74b8-4d53-ab33-5dc590cedc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.filter(pl.col(\"genres\").str.contains(\"Horror\"))\n",
    "    .join(movie_rating_df, left_on=\"id\", right_on=\"movie_id\")\n",
    "    .select(pl.col(\"rating\").mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f6fe9-574e-493d-84f7-6573d0a2a3b1",
   "metadata": {},
   "source": [
    "How does that compare to mystery movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54158c04-39e5-4dfc-ab57-bd492484aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.filter(pl.col(\"genres\").str.contains(\"Mystery\"))\n",
    "    .join(movie_rating_df, left_on=\"id\", right_on=\"movie_id\")\n",
    "    .select(pl.col(\"rating\").mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd3bce-64a6-4180-9113-3aa2231abf4f",
   "metadata": {},
   "source": [
    "Create a dataset containing the all the Science Fiction movies and their reviews. Only include fields you think are interesting.\n",
    "\n",
    "Save your dataset as a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de7f7e-7769-4311-8713-ce0000f97cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    movie_df.filter(pl.col(\"genres\").str.contains(\"Science Fiction\"))\n",
    "    .join(movie_rating_df, left_on=\"id\", right_on=\"movie_id\")\n",
    "    .select(\n",
    "        [\n",
    "            \"original_title\",\n",
    "            \"genres\",\n",
    "            \"release_date\",\n",
    "            \"runtime\",\n",
    "            \"budget\",\n",
    "            \"revenue\",\n",
    "            \"popularity\",\n",
    "            \"user_id\",\n",
    "            \"rating\",\n",
    "        ]\n",
    "    )\n",
    "    .write_parquet(\"temp/horror_movie_ratings.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949301d2-9545-4138-a727-ca860491ea1e",
   "metadata": {},
   "source": [
    "### Explore a job change dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2bb1a6-5d89-4716-a4eb-cc4d753c9120",
   "metadata": {},
   "source": [
    "Kaggle has a [dataset](https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists?datasetId=1019790&sortBy=voteCount&select=aug_train.csv) that documents whether data scientists are looking to change jobs.\n",
    "\n",
    "It has the following features.\n",
    "\n",
    "- `enrollee_id` : Unique ID for candidate.\n",
    "- `city`: City code.\n",
    "- `city_development_index` : Developement index of the city (scaled).\n",
    "- `gender`: Gender of candidate\n",
    "- `relevent_experience`: Relevant experience of candidate\n",
    "- `enrolled_university`: Type of University course enrolled if any\n",
    "- `education_level`: Education level of candidate\n",
    "- `major_discipline` :Education major discipline of candidate\n",
    "- `experience:` Candidate total experience in years\n",
    "- `company_size`: No of employees in current employer's company\n",
    "- `company_type` : Type of current employer\n",
    "- `last_new_job`: Difference in years between previous job and current job\n",
    "- `training_hours`: training hours completed\n",
    "- `target`: 0  Not looking for job change, 1  Looking for a job change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb0d51-15df-47b0-8937-76da52e25987",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_change_df = pl.read_csv(\"data/data-scientist-job-change.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92305d1-a374-4d21-85da-aeb11955cc09",
   "metadata": {},
   "source": [
    "Explore and clean this dataset.\n",
    "\n",
    "Some things you might consider are\n",
    "\n",
    "- Missing data\n",
    "- Distribution of individual features\n",
    "- Relationships between features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c58d6-f54f-488c-a7b1-7323a016c104",
   "metadata": {},
   "source": [
    "For example, look at how education level interacts with interest in changing job.\n",
    "\n",
    "We create a custom ordering on `education_level` to sort the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cae8dc-7823-4abf-9cbd-eb25673783be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pl.StringCache():\n",
    "    education_level = [\"Primary School\", \"High School\", \"Graduate\", \"Masters\", \"Phd\"]\n",
    "\n",
    "    pl.Series(education_level).cast(pl.Categorical)\n",
    "    \n",
    "    df_ = job_change_df.with_columns(\n",
    "        pl.col(\"education_level\").cast(pl.Categorical)\n",
    "    )\n",
    "    \n",
    "(\n",
    "    df_\n",
    "    .filter(\n",
    "        pl.col(\"education_level\").is_not_null(),\n",
    "    )\n",
    "    .group_by([\"education_level\", \"target\"])\n",
    "    .agg(\n",
    "        pl.len().alias(\"count\"),\n",
    "    )\n",
    "    .sort(\n",
    "        pl.col(\"education_level\").to_physical()        \n",
    "    )\n",
    "    .plot.bar(\n",
    "        x = alt.X(\"sum(count)\", title=None),\n",
    "        y = alt.Y(\"education_level\", sort=None),\n",
    "        color=\"target\",\n",
    "    )\n",
    "    .properties(\n",
    "        width=500,\n",
    "        height=200,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aea271-0e16-44eb-8080-d22d62b27e2c",
   "metadata": {},
   "source": [
    "## Hands-on exploration of OKCupid data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c05759-b634-47a4-b30b-9dce6e9f5f34",
   "metadata": {},
   "source": [
    "Open the OKCupid dataset and explore it. Most of the fields are categorical.\n",
    "\n",
    "How clean is the data?\n",
    "\n",
    "Can you identify any correlations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d934b2-33d9-4165-9ef0-fe3a559b2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cupid_df = pl.read_csv(\"data/ok-cupid.csv\", infer_schema_length=None)\n",
    "\n",
    "ok_cupid_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
